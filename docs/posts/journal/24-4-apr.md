---
title: 2024 April
---

## 2 Tuesday

### 2.todo

- [x] 2.1 Show using Chrome all credentials received and applied.
- [x] 2.2 Review Antonio's Code
- [ ] 2.3 Review Proposal to have Chrome Stipplo with keywords checker.
- [ ] 2.4 Review into Genetic and Continue.
- [ ] 2.5 Adding all books algorithms learnt so far into anki.
- [x] 2.6 Test DDPortal
- [ ] 2.7 Dev + Stage environment event enhancer.



### 2.1 Show using Chrome all Credentials received and Applied

![](../../../img/Pasted%20image%2020240402104825.png)


### 2.2 Review Antonio's Code


#### Test 1
Actions
- [x] 15:57 Start typing in Obsidian
- [x] 15:58 Continue typing in Obsidian
- [x] 15:59 Break in the middle into a different application
- [x] 16:01: Finish so that to see the events.

Expectations
- [ ] 15:58 mid: an event indicating 15:57:xx - 15:57:59
- [ ] 15:59 mid: event indicating 15:58:00 - 15:58:59
- [ ] 16:00 mid event indicating 15:59:xx - 15:59:xy Obsidian


Sent at: April 2, 2024, 10:57:51 (UTC-04:00)
+ With some events from the past together.
![](../../../img/Pasted%20image%2020240402111518.png)

- Sent at: April 2, 2024, 10:59:25 (UTC-04:00)

![](../../../img/Pasted%20image%2020240402111648.png)

**What I received and conclusions**

I can see the following fixes were implemented:
- The event and attached interactions and the new interactions per minute are correct
- Event name and windows title seems to be  correct
Here are some issues remaining/new:
- a new event should have been sent every minute (new)
- the end_date of the event should been the last second of that minute e.g. `2024-04-02T14:56:59Z` instead of `0001-01-01T00:00:00`


#### Test 2 - Longer Obsidian Writing

**What I did**

11:40 Start Writing in Obsidian
Continue typing in Obsidian from 11:40 to the middle of 11:48
11:48 Finish Writing change pages


**What I expected**

- Around 8-9 staging events sent
- Each minute form 11:40 to 11:48 to receive an update regarding my typing
- At around 11:49 Receive my last event containing (The long action of) Obsidian.

**What I received**

- 2 staging events only
- The long Obsidian Event with updates (should be around 8-9 events) are missing

Thus, around 11:49 I would expect the last Obsidian Event to be sent.

This doesn't make much sense:

![](../../../img/Pasted%20image%2020240402115201.png)

> This is incorrect around 8 events to be sent once every minute (random seconds)


Event Sent at: April 2, 2024, 11:41:50

> Here older events.


![](../../../img/Pasted%20image%2020240402121057.png)
Event Sent at: April 2, 2024, 11:50:14

Last event:

![](../../../img/Pasted%20image%2020240402121501.png)
> The event_date of event type: "WIN_AGENT_START" should be in UTC (Is in Local timestamp)



#### Test 3 

**My Actions:**
--- Test 3 ----

12:47: Start writing in Obsidian
Continued Typing in Obsidian until half of 12:5
12:57 Swapped to Firefox.
12:59 Stop sending events.

**Expected:**

- Around 10-12 Staging Events being sent to bucket
- Every minute to receive an event containing Obsidian, with updates of how are things working (From 12:48 to 12:58)
- at 12:58 receiving some mixture of events containing the last Obsidian Update + other events

**What I received**

- 2 Staging Events being sent to the bucket
- The long Obsidian event with updates is missing (the 10 files and events from 12:48 to 12:58)
- I have attached the json files received.


![](../../../img/Pasted%20image%2020240402130411.png)


### 2.3 Review Proposal to have Chrome with keywords checker.

It should contain create a prototype to have the following on Chrome Extension

- Be able to check the keywords (skill words) on the selected description.
- Be able to create a 
- Be able to track the application
- Be able to take notes on the application.



It would also be quite the interesting side project for it.

You could event make the trading tool as a side project to have it 

![](./../../../img/2024-04-02-13-01-06.png)

### 2.6 DDPortal

Use the following credentials:

```
nwang@platinumfilings.com
Da!
```

For Windows events test for date: 2024-03-19
![](../../../img/Pasted%20image%2020240402134658.png)


For salesforce check for: `2023-05-16`

![](../../../img/Pasted%20image%2020240402141214.png)

Looking fine to me:

![](../../../img/Pasted%20image%2020240402141614.png)


### 2.7 Dev + Stage environment event enhancer.

- Dev Environment
- Stage Environment


- [x] Create SQS Replicas for each environment.

![](../../../img/Pasted%20image%2020240402142854.png)

Lets remove The unused staging queues. To keep only standard ones (Remove Standard)


```
QUEUE_URL=https://sqs.us-east-1.amazonaws.com/796522278827/dev-staging-in-sqs
```


![](../../../img/Pasted%20image%2020240402143458.png)

> Is this the upper limit problem of storing tings in the SQS message instead of the S3?

Now that they are added:

![](../../../img/Pasted%20image%2020240402143652.png)

- [ ] Connect the file locations to the distinct processing sqs to do different jobs.

Modify the following so that: if SQS_URL is a string separated with ',' to loop and send the events:

```python
response = sqs.send_message(
        QueueUrl=SQS_URL,
        DelaySeconds=10,
        MessageAttributes={
            'guid': {
                'DataType': 'String',
                'StringValue': ddrequest['guid'],
            },
            'organization': {
                'DataType': 'String',
                'StringValue': d['organization']
            },
            'connector': {
                'DataType': 'String',
                'StringValue': d['connector']
            },
            'integration': {
                'DataType': 'String',
                'StringValue': d['integration']
            },
            'date': {
                'DataType': 'String',
                'StringValue': datetime.now().isoformat()
            },
            's3key': {
                'DataType': 'String',
                'StringValue': s3key
            },
            'body_embedded': {
                'DataType': 'String',
                'StringValue': str(embed_body)
            }
        },
        MessageBody=(sqsbody)
    )
```

Send the message to each
```python

SQS_URLs = SQS_URL.split(',')

for url in SQS_URLs:
    response = sqs.send_message(
        QueueUrl=url,
        DelaySeconds=10,
        MessageAttributes={
            'guid': {
                'DataType': 'String',
                'StringValue': ddrequest['guid'],
            },
            'organization': {
                'DataType': 'String',
                'StringValue': d['organization']
            },
            'connector': {
                'DataType': 'String',
                'StringValue': d['connector']
            },
            'integration': {
                'DataType': 'String',
                'StringValue': d['integration']
            },
            'date': {
                'DataType': 'String',
                'StringValue': datetime.now().isoformat()
            },
            's3key': {
                'DataType': 'String',
                'StringValue': s3key
            },
            'body_embedded': {
                'DataType': 'String',
                'StringValue': str(embed_body)
            }
        },
        MessageBody=(sqsbody)
    )
```


Internal Server Error:

![](../../../img/Pasted%20image%2020240402151158.png)

![](../../../img/Pasted%20image%2020240402151410.png)

> Is this because?

Wait what?

![](../../../img/Pasted%20image%2020240402151723.png)

How come did it send any event before? If the syntax really didnt change that much>



![](../../../img/Pasted%20image%2020240402152007.png)

Literally has the same **Access Policy**

![](../../../img/Pasted%20image%2020240402152211.png)


The lets check the IAM Policies.

![](../../../img/Pasted%20image%2020240402152345.png)


Changed to the following:

```
"Resource": [
                "arn:aws:logs:us-east-1:796522278827:log-group:/aws/lambda/dev-dd-lambda-incoming-connector:*",
                "arn:aws:dynamodb:us-east-1:796522278827:table/dev-dd-incoming-connectors",
                "arn:aws:s3:::dev-stage-in/*",
                "arn:aws:sqs:us-east-1:796522278827:*"
            ]
```


That looks about right.

![](../../../img/Pasted%20image%2020240402153036.png)

![](../../../img/Pasted%20image%2020240402154821.png)

> Probably because of the IP issues.


![](../../../img/Pasted%20image%2020240402155658.png)

![](../../../img/Pasted%20image%2020240402155936.png)


![](../../../img/Pasted%20image%2020240402160318.png)

![](../../../img/Pasted%20image%2020240402164158.png)

Here you can see that the 1 minute trigger is not working effectively.


**Testing for the extensions**

## 3 Wed


### 3.1 *Identifying issues.*


```
UPDATE processing_tracker SET status = %s, end_time = %s WHERE processing_guid = %s
INFO:Processing Ended for: 7f0fe84b-6c27-78e4-adfd-235f8f306eb9
ERROR:ERROR: An error occurred (ResourceNotFoundException) when calling the PutLogEvents operation: The specified log stream does not exist.
```

Log Stream errors should not affect the ending.
Also, I know that they are refreshed every x Amount but still.


*Chrome issues*

- How about idle?
- It will still send the event on idle?
- Ensure that events are send once a minute.


This is. To be discussed as well. if it should be handled by the backend or what Or for example the Timeslots.

In my opinion it should be handled by the backend. And idle or not's are just depicted as accurately (and simple) as possible from the connector.


**S3 Events**
![](../../../img/Pasted%20image%2020240404104340.png)

> Here you have evidence that it has been sent at least! once a minute. It also has contingency backups such as when it suspects that the extensions will be meddled with. Which is correct.


*Windows Issues*

- Pull Last version
- Check 'up with the events. If it is sending every one minute as expected. 


### 3.2 Testing Hypothesis

- The space combat is done though AI.
- The in person exploration then that's would make sense. Specially small mining or ship recovery investigations.
- The game should start with the ability to "engage combat" using ai just a percentage match.
- How do you combine weapon selection effectiveness though? 
	- well. How about  engaging or recreating simulated scenarios?
	- How about AI Recommended weapons? Or should I provide that for users?
	- What would be the scenarios?
		- Close
			- Explorations, entering
		- Medium
			- Houses, middle ground. Pretty effectiveness.
		- Long
			- Open Scenarios
	- The best thing here?
		- Everything can be done either in the command line with no risk whatsoever. Just math functions.
		- I could probably run them using Python though. And make it Pygame but nah. I want to genuinely Practice C#
- Prototyping
	- Perhaps should be done on C# to avoid any kind of risks


**Designing Code Architecture**

How to run things? How about the architecture of the code? What needs to be done for sake of practice? How to make this compatible with Unity? How about the Unit tests? If you want to hide the Unit tests or just test them like X? How about running it using Python? Just some crazy idea of using data science to have fun instead?

Lets review point by Point:

- Probably Unit Test can be evaluated as such. with some of the worlds most miscellaneous titles and filenames? yeah.
- How about in like a python Jupyter notebook structure? I mean that could work of course. But then loses the transmutability that c# has by default.
- The cool thing about running it on JS would be that I could have that online.
- The cool thing about running it on C# is that I could have that...
- Well, just overall the idea of writing in C# sounds appealing because I could covert run my tests and etc. 
- While effectively learning a useful tool. 
- Perhaps would be even MORE useful to have that as an API design strategy? using API to interact and having Swagger on top of it could be quite the interesting proposal. The same can be done with Spring for other more logic oriented products.
- Naming's could be hidden by having to appeal the more generic structures such as:
	- Models
	- 

So in conclusion:

- [x] Learn how to do Backend Development by developing g.

Now I do have a concern here:

- How would I be able to learn other concepts from the backend Stage? Such as uploading images, handling requests, cleaning work? Authentication as well?
- Well I think you should **attempt** to make it such that it handles also the authentication and etc. for an online kind of API once you have at least handled things like 
- Also displaying images might be useful as well try to manipulate visualizations and return them for for them to be handled.
- Backend LOGC while maintaining the best practices of documentation and creating developers oriented API might be a good idea
- Also streaming perhaps allow streaming of certain sounds etc. And the idea for it would be to allow any front end to be able to use the backend for replicating or creating a front end for the project. That might be even more interesting in moping. However this would make more sense for some kind of WebSocket. (Which is different.)
- Therefore you should also learn what are the best choices for socket based as well, as non socket simple REST requests, that handle the updates of an user.
- Interesting. It could and perhaps should handle things not to be always using SOCKET, but just some REST endpoints to update the economy.
- And then perhaps combine some graph and other interesting ways into having it there.
- But right, from socket there is a different type of entries.
- In the same case can be said about or even individuals. Just post the updated progress every so often or just save the Api and await until interesting decisions are made, since they are all requests to update the schedule or rnd.


## 4 Thursday


### 4.1 Talking Points

*Here some talking points remaining to go with Danny.*

- [x] Control of the 2 minutes
- [ ] How are we collecting Idle? How about 
- [ ] How should the description be for each activity?


e.g. for Chrome
- Visited {{url}}
- Downloaded 2 Files from {{url}}
- Uploaded 2 files from {{url}} of size {{sizeNumber}}

e.g. Salesforce
- Did X
- 

e.g. for 


- [ ] Many events on the Screen could be improved by adding:
	- [ ] Endtime
- [ ] Categorization for Chrome + Windows Events ONLY to be ACTIVITY when:
	- [ ] Is Start Timeslot (first)
	- [ ] Has Interaction embedded
- [ ] When clicking on the heatmap be more specific in the Activity


**Making sure that all Processing is properly documented.**




### 4.2 Chrome quality Control

- [x] Check if it is sending events even if you are not there? <- This would be a bug.
- [x] Check if chrome sends once a minute.


### 4.3 Windows Quality Control


Example Right now:
- 1:31pm started working on an Obsidian Document
- 1:3Xpm 



### 4.4 Documenting & Testing

![](../../../img/Pasted%20image%2020240404133718.png)

> Around this time you can see that I am pulling for the code.

Here are some interesting manual tests. It would be quite essential to add this tests and `latest` results as per when they were passed.

- Around at 1:37  I started editing again the Obsidian Document
- Around 1:42 to stop editing and stopping the events sending reports.

I will keep editing. This is what I am expecting:

- [x] Per minute event sent from Windows. 
- [x] No event sent from Chrome (Except for the last wrap up).

> Chrome Events
![](../../../img/Pasted%20image%2020240404134356.png)

Great, Here can be seen that non of those are being sent.


> Windows Events.
> ![](../../../img/Pasted%20image%2020240404134512.png)

Hmm interesting. only **two relevant** events were received.

![](../../../img/Pasted%20image%2020240404140321.png)

> Last events: Can be seen that one event is sent at 15:39 then no more events, not even rejections.
> ![](../../../img/Pasted%20image%2020240404140337.png)


Lets see from the Windows Logger Perspective?

Hypothesis:
- It is not sending because when the app was "loading" it didn't capture the start of the first event!
- Re test by: play around a minute, make sure is running and then move to the long term event.


That seems to be the case?

In the previous case, it did seem to work fine: but did it really? Because it might been that it was sending the swap of events.

Lets see. I waited a little bit before at 2:20 start working on Obsidian events.
- Alright so let's start here and then NOT switch for after 10 minutes of editing
- 2:21 - 2:29
- Should expect a total of around 8-7 events


![](../../../img/Pasted%20image%2020240404142943.png)

Which IS the case.


Okay, this seems as a problem:

![](../../../img/Pasted%20image%2020240404143022.png)

It should be instead indicating UPDATE event.

![](../../../img/Pasted%20image%2020240404143518.png)

As can be seen, they are being interpreted as different events. Lets review the S3 files.

Lets turn off chrome and test this.

Good, they have the same span guid:

![](../../../img/Pasted%20image%2020240404143701.png)
![](../../../img/Pasted%20image%2020240404143711.png)

And there you go:

![](../../../img/Pasted%20image%2020240404143932.png)


**How could this even happen?**
![](../../../img/Pasted%20image%2020240404145652.png)

There is should be around 10\*60 duration around 600s instead it shows only 111. Thus my guess, is that when the events are extended, they are not really extended (duration wise) requires to be recalculated

Lets see from the timeslot perspective:

```
79a37140-8ddf-4563-9074-8f3dd6401f49
```
![](../../../img/Pasted%20image%2020240404150155.png)

Lets query for such:

![](../../../img/Pasted%20image%2020240404152410.png)

So clearly can be seen here that they are being 'recreated' from the timeslots.

Also interesting here:

![](../../../img/Pasted%20image%2020240404152552.png)

keystrokes and mouseclicks are Not being mapped correctly (For windows at least it seems)

```json
  "interactions": [
        {
          "date": "2024-04-04T18:20:00",
          "keys": 149,
          "mouse": 5
        },
        {
          "date": "2024-04-04T18:21:00",
          "keys": 251,
          "mouse": 0
        },
        {
          "date": "2024-04-04T18:22:00",
          "keys": 32,
          "mouse": 4
        },
        {
          "date": "2024-04-04T18:23:00",
          "keys": 62,
          "mouse": 3
        },
        {
          "date": "2024-04-04T18:24:00",
          "keys": 106,
          "mouse": 2
        },
        {
          "date": "2024-04-04T18:25:00",
          "keys": 142,
          "mouse": 3
        },
        {
          "date": "2024-04-04T18:26:00",
          "keys": 131,
          "mouse": 4
        }
      ],
```


Here it is asking for the following in Events Data
```json
"mouse_clicks", "keystrokes", "processing_guid",
```


```python
  

    @staticmethod

    def get_publishing_keys():

        """Returns all the attributes of the class.

  

        Returns:

            List[str]: List of attributes.

        """

        return [

            "event_guid", "organization_guid",

            "hour", "minute", "day", "month", "year", "week", "weekday",

            "hour_local", "minute_local", "day_local", "month_local", "year_local", "week_local", "weekday_local",

            "mouse_clicks", "keystrokes", "processing_guid",

            "ts1", "ts5", "ts10", "ts15", "tl1", "tl5", "tl10", "tl15"

        ]
```


Here the event Data model snippet:

```python
#  These are the only ones that are not in the original model

 mouse_clicks: dict = {},
 keystrokes: dict = {},
```


Let's have the dictionary:

- Let's evaluate here: 

- This means that it wont be able to match. So how do I match it? Would make sense to have such "consistency" matching done at the level of adapting engine.

```
Searching for year_month_day_minute 2024-04-04T19:42
Mouse Clicks {'2024-04-04T19:42:00': 1}
Keystrokes {'2024-04-04T19:42:00': 0}
```

I wonder why it is unable detect such duplication here?

```
Keystrokes {}
Updating 1 events
Inserting 3 events
Error inserting event: duplicate key value violates unique constraint "event_guid_key"
DETAIL:  Key (guid)=(e82c0f75-5ad5-401b-a7a7-99cc4306bcb5) already exists.

event
{'action_type': 'ACTIVITY',
 'app': 'RemoteApp (PID: 31820)',
 'app_type': None,
 'application': 'mstsc',
 'description': None,
 'duration': 1,
```


![](../../../img/Pasted%20image%2020240404161951.png)


Lets find why this is the case?

```
Updating 1 events
Inserting 7 events
Error inserting event: duplicate key value violates unique constraint "event_guid_key"
DETAIL:  Key (guid)=(52cc15a7-cfea-4470-b466-a9dffea6b58e) already exists.
```


**Further Inspection Results**

```
Existing Events fetch from db []
Querying for existing events SELECT guid, end_time, end_time_local FROM event WHERE guid IN (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s) ['123f0c48-7a1a-4d0d-85a0-13ded1930481', '123f0c48-7a1a-4d0d-85a0-13ded1930481', '5735feb3-5a6b-49d0-8fc2-598147d8dc54', '5735feb3-5a6b-49d0-8fc2-598147d8dc54', '73fb424f-e192-4330-a56f-a0c899512ae3', '73fb424f-e192-4330-a56f-a0c899512ae3', '6984889b-e82a-4c3d-af3d-4e1bee8cad23', '6984889b-e82a-4c3d-af3d-4e1bee8cad23', 'd412c088-1095-4430-b3f0-6c905dc72275', 'd412c088-1095-4430-b3f0-6c905dc72275', '18764283-f3c9-4ee5-bdf8-7805274990ae', '013e421e-5428-4c01-bc8a-6f9b6e7d54d5', '647bb40c-d91f-4b8e-9100-23adfc090d33', '647bb40c-d91f-4b8e-9100-23adfc090d33', '82e6b906-b4cb-4def-aaea-d24b79608ff1', '82e6b906-b4cb-4def-aaea-d24b79608ff1', '5223baa3-66b1-47b7-9711-86ff26b70cea', '5223baa3-66b1-47b7-9711-86ff26b70cea', '597453d5-b571-4ddf-b97a-f3b852d89819', '597453d5-b571-4ddf-b97a-f3b852d89819', 'e9c32930-999a-4469-85ca-8b3069d8430d', 'e9c32930-999a-4469-85ca-8b3069d8430d', '86c9375c-934f-4b90-b30b-55ca3a250ec3', '17ff0277-39a5-4144-af65-b73ce534e48d', 'fff1cdea-60c5-4751-8487-99257b247638', 'fff1cdea-60c5-4751-8487-99257b247638', 'fff1cdea-60c5-4751-8487-99257b247638', '02bbbc7a-fd5d-44f5-8fe0-9e4cf5d22ffd', '02bbbc7a-fd5d-44f5-8fe0-9e4cf5d22ffd', '7957b1a8-a835-439a-9bf9-6fc072c5b8ae']
```


Here, it seems that the events were not collapsed. So let's start reviewing:

```python 

# Duplicated GUIDS? Uncomment the following:

print("Collapsed Events", len(collapsed_events))

print("Event Data GUID List", [eventData.event_guid for eventData in eventDataList])

print("Collapsed event GUID List", [eventData.event_guid for eventData in collapsed_events])



return collapsed_events
```


- And meanwhile lets inspect

Oh! Its not even being called here:
![](../../../img/Pasted%20image%2020240404165303.png)

```python
```


![](../../../img/Pasted%20image%2020240404170317.png)

and duration 0.

Why is the case?
> don't know but it was fixed.

Lets try the following:
![](../../../img/Pasted%20image%2020240404171753.png)

```python
placeholders = ', '.join(['%s'] * len(timeslots_guids))

select_sql = f"SELECT ts1, event_guid FROM timeslot WHERE event_guid IN ({placeholders})"

jobService.cursor.execute(select_sql, timeslots_guids)

existing_timeslots = jobService.cursor.fetchall()

existing_timeslots_ts1 = set([existing_timeslot['ts1'] for existing_timeslot in existing_timeslots])



# Not Unique GUID Errors? Uncomment the following:

# print("Existing Timeslots fetch from db", existing_timeslots)

# print("Querying for existing timeslots", select_sql, timeslots_guids)



# Clean the query arguments

for timeslot in timeslots:

	if timeslot.ts1 in existing_timeslots_ts1:

		print("Skipped", timeslot.ts1, timeslot.event_guid)

		continue

	values = []
```

### 4.5 Revisiting Front End Visualizations (Green Red Timeslot Screen.)

- Since we are not taking idle in the processing and connectors, we are leaving that to be determine by the processor.
- How should we determine that?
- And the timeslots are created multiple times for each event of the same SpanGUID.
- Is that what we determined to be the fairest method of finding out the Timeslots? Right now it just sends all again, and avoid sending if the timeslot was found.
- Also the event doesn't distinguish between I clicked on a windows, went to bathroom and came back and started clicking again.


### 4.6 Unique Timeslots Only Patch



- Making sure that the processor is able to skip those where the event_guid and ts1 are not the same.
- Hmm, lets review then, if after the expected time,  

![](../../../img/Pasted%20image%2020240404175833.png)

- This is in fact correct:
![](../../../img/Pasted%20image%2020240404180008.png)

## 8 Monday

### 8.todo


### 8.1 Design Talk

- [ ] How are we collecting Idle? How about 
- [ ] How should the description be for each activity?
- [ ] Pages should refresh automatically (for timeslots screen) as well as manually through a button.
- [ ] Request Local permission to access Stage through vpn?












## 9 Tuesday


### 9.todo


- [ ] Allow for access.

```
stage-dd-portal-database.cby8aaf6nvlw.us-east-1.rds.amazonaws.com
sL06s4nEISamuXI7

```

### 9.1   Debug for Heartbeat


![](../../../img/Pasted%20image%2020240409102337.png)
> What is the reason for the greenlights?

Am I perhaps registering as ACTIVE? ensure all are only if type is `activity`. not aplicable.


Password changed to:
nwang@platinumfilings.com

```
nwang@platinumfilings.com
TKZ&#3P#+AGt9*j
```


## 16 - MS And the selection of options.

- There is 2 paths. One is the cert and learn path. 
  - The problem with this option is that most jobs are being outsourced.
  - And also if you want to qualify for jobs that are not. Then you need some crazy security clearance
- The other one has to do with going on your own bus.
  - I respect this path given the chance more. 
  - Is more clea I like it. f-cs. f doing as a sl.  
- The other is the following:
  - Underp and grow the product line. Idea is to get in in low level.
  - Work tpgetjer wotj a team to make it possible.
- I am thinking of the following:
  - go with the grow path. Grow into the business, learn as a sl. and slowly plot to start your own bs. Learn all the aspects you need to take.
  - And also start thinking about what are the paths to do such.
  - And apply! outside or by the line of products
  - Also you need to conserve energy. Avoid risking your health.






### 16.2 Debug for targetting and tabs






## End 